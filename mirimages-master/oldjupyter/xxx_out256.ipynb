{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": true,
    "inputHidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at 'In [17]'.</span>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<span style=\"color:red; font-family:Helvetica Neue, Helvetica, Arial, sans-serif; font-size:2em;\">An Exception was encountered at 'In [17]'.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "papermill": {
     "duration": 2.647417,
     "end_time": "2019-11-21T19:06:23.338762",
     "exception": false,
     "start_time": "2019-11-21T19:06:20.691345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "papermill": {
     "duration": 0.067436,
     "end_time": "2019-11-21T19:06:23.427865",
     "exception": false,
     "start_time": "2019-11-21T19:06:23.360429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/data2/csv/intell_residual_train.csv')\n",
    "val_df = pd.read_csv('/data2/csv/intell_residual_valid.csv')\n",
    "test_df = pd.read_csv('/data2/csv/intell_residual_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "papermill": {
     "duration": 0.02983,
     "end_time": "2019-11-21T19:06:23.486284",
     "exception": false,
     "start_time": "2019-11-21T19:06:23.456454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train_df = train_df[train_df['abcd_site']==16]\n",
    "#val_df = val_df[val_df['abcd_site']==16]\n",
    "#test_df = test_df[test_df['abcd_site']==16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "papermill": {
     "duration": 0.026853,
     "end_time": "2019-11-21T19:06:23.532713",
     "exception": false,
     "start_time": "2019-11-21T19:06:23.505860",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "patht1 = './data_T1_lowerres/'\n",
    "patht2 = './data_T2_lowerres/'\n",
    "pathdef = './data_defusion_lowerres/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "papermill": {
     "duration": 0.027659,
     "end_time": "2019-11-21T19:06:23.584868",
     "exception": false,
     "start_time": "2019-11-21T19:06:23.557209",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "patht1 = '/data/home/benedikt_d_schifferer/data_T1_T2_201909/'\n",
    "patht2 = '/data/home/benedikt_d_schifferer/data_T1_T2_201909/'\n",
    "#pathdef = './data_def_lowerres_cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "papermill": {
     "duration": 0.796218,
     "end_time": "2019-11-21T19:06:24.401646",
     "exception": false,
     "start_time": "2019-11-21T19:06:23.605428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_files = glob.glob(patht1 + '*_T1.nii.gz') + glob.glob(patht2 + '*_T2.nii.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "papermill": {
     "duration": 0.030747,
     "end_time": "2019-11-21T19:06:24.453253",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.422506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_subject_id(text):\n",
    "    text_split = text.split('sub-')[1]\n",
    "    text_split = text_split.split('_', 1)\n",
    "    return(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "papermill": {
     "duration": 0.046195,
     "end_time": "2019-11-21T19:06:24.525087",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.478892",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_subjects = [extract_subject_id(x)[0] for x in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "papermill": {
     "duration": 0.035038,
     "end_time": "2019-11-21T19:06:24.584729",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.549691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_subjects = list(dict.fromkeys(all_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "papermill": {
     "duration": 0.03137,
     "end_time": "2019-11-21T19:06:24.640669",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.609299",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11373"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "papermill": {
     "duration": 0.029769,
     "end_time": "2019-11-21T19:06:24.697671",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.667902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_filenames(sub, all_files):\n",
    "    return([x for x in all_files if sub in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "papermill": {
     "duration": 0.040398,
     "end_time": "2019-11-21T19:06:24.760164",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.719766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/data/home/benedikt_d_schifferer/data_T1_T2_201909/sub-NDARINVU8D0FE3D_T1.nii.gz']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames(all_subjects[0], all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "papermill": {
     "duration": 0.04354,
     "end_time": "2019-11-21T19:06:24.837076",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.793536",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def parse_subject(subject, files):\n",
    "    for file in files:\n",
    "        img = nib.load(file)\n",
    "        data = np.array(img.dataobj)\n",
    "        if '_T1.' in file:\n",
    "            t1 = data.copy()\n",
    "            if t1.shape != (256,256,256):\n",
    "                print('error')\n",
    "        if '_T2.' in file:\n",
    "            t2 = data.copy()\n",
    "            if t2.shape != (256,256,256):\n",
    "                print('error')\n",
    "        if '_AD.' in file:\n",
    "            ad = data.copy()\n",
    "            if ad.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_FA.' in file:\n",
    "            fa = data.copy()\n",
    "            if fa.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_RD.' in file:\n",
    "            rd = data.copy()\n",
    "            if rd.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_MD.' in file:\n",
    "            md = data.copy()\n",
    "            if md.shape != (64,64,64):\n",
    "                print('error')\n",
    "    example = tf.train.Example(features = tf.train.Features(\n",
    "        feature = {\n",
    "            't1':_bytes_feature(t1.tostring()),\n",
    "            't2':_bytes_feature(t2.tostring()),\n",
    "            'subjectid':_bytes_feature(subject.encode('utf-8'))\n",
    "        }))\n",
    "    return(example)\n",
    "\n",
    "def convert_to_records(all_subjects, all_files, sample=100, path = 'test4.tfrecords'):\n",
    "    print('writing to {}'.format(path))\n",
    "    counter = 0\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for i in range(min(len(all_subjects), sample)):\n",
    "            subjectid = all_subjects[i]\n",
    "            files = get_filenames(subjectid, all_files)\n",
    "            if len(files)==2:\n",
    "                example = parse_subject(subjectid, files)\n",
    "                writer.write(example.SerializeToString())\n",
    "                if i%100==0:\n",
    "                    print('writing {}th image'.format(i))\n",
    "            else:\n",
    "                print(subjectid)\n",
    "                print(files)\n",
    "                print('missing images')\n",
    "                counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "papermill": {
     "duration": 0.040711,
     "end_time": "2019-11-21T19:06:24.898980",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.858269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df['subjectkey'] = train_df['subjectkey'].str.replace('_', '')\n",
    "val_df['subjectkey'] = val_df['subjectkey'].str.replace('_', '')\n",
    "test_df['subjectkey'] = test_df['subjectkey'].str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "papermill": {
     "duration": 0.03939,
     "end_time": "2019-11-21T19:06:24.967079",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.927689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "papermill": {
     "duration": 2563.55018,
     "end_time": "2019-11-21T19:49:08.540677",
     "exception": false,
     "start_time": "2019-11-21T19:06:24.990497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to /data2/t1t2_test_allimages_256_v4_new.tfrecords\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 0th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 100th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 200th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 300th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 400th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 500th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 600th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 700th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 800th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 900th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 1000th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 1100th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing 1200th image\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "#convert_to_records([x for x in all_subjects if x in list(train_df['subjectkey'])], all_files, sample=100000, path = '/data2/t1t2_train_allimages_256_v4.tfrecords')\n",
    "#convert_to_records([x for x in all_subjects if x in list(val_df['subjectkey'])], all_files, sample=100000, path = '/data2/t1t2_val_allimages_256_v4.tfrecords')\n",
    "convert_to_records([x for x in all_subjects if x in list(test_df['subjectkey'])], all_files, sample=100000, path = '/data2/t1t2_test_allimages_256_v4_new.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "papermill": {
     "duration": 1.336532,
     "end_time": "2019-11-21T19:49:09.906141",
     "exception": true,
     "start_time": "2019-11-21T19:49:08.569609",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'error' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-ded28046d863>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0merror\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'error' is not defined"
     ]
    }
   ],
   "source": [
    "error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_files = [x for x in all_subjects if x in list(train_df['subjectkey'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for subjectid in train_files:\n",
    "    files = get_filenames(subjectid, all_files)\n",
    "    for file in files:\n",
    "        img = nib.load(file)\n",
    "        data = np.array(img.dataobj)\n",
    "        if '_T1.' in file:\n",
    "            t1 = data.copy()\n",
    "            if t1.shape != (64,64,64):\n",
    "                print('t1 shape')\n",
    "                print('error')\n",
    "                print(file)\n",
    "            if t1.dtype != 'uint8':\n",
    "                print('t1 type')\n",
    "                print('error')\n",
    "                print(file)\n",
    "        if '_T2.' in file:\n",
    "            t2 = data.copy()\n",
    "            t2 = t2.astype(np.float32)\n",
    "            if t2.shape != (64,64,64):\n",
    "                print('t2 shape')\n",
    "                print('error')\n",
    "                print(file)\n",
    "            if t2.dtype != 'float32':\n",
    "                print('t2 type')\n",
    "                print('error')\n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "t2.astype(np.float32).dtype == 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!du -sh t1t2_train_sample100.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tfDataSet = tf.data.TFRecordDataset('t1t2_val_site16_allimages_v4.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "read_features = {\n",
    "    't1': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    't2': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'ad': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'fa': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'md': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'rd': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'subjectid': tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_(serialized_example, decoder = np.vectorize(lambda x: x.decode('UTF-8'))):\n",
    "    example = tf.io.parse_single_example(serialized_example, read_features)\n",
    "    t1 = tf.reshape(tf.io.decode_raw(example['t1'], tf.int8), (64,64,64))\n",
    "    t2 = tf.reshape(tf.io.decode_raw(example['t2'], tf.float32), (64,64,64))\n",
    "    ad = tf.reshape(tf.io.decode_raw(example['ad'], tf.float32), (64,64,64))\n",
    "    fa = tf.reshape(tf.io.decode_raw(example['fa'], tf.float32), (64,64,64))\n",
    "    md = tf.reshape(tf.io.decode_raw(example['md'], tf.float32), (64,64,64))\n",
    "    rd = tf.reshape(tf.io.decode_raw(example['rd'], tf.float32), (64,64,64))\n",
    "    subjectid = example['subjectid']\n",
    "    return ({'t1': t1, 't2': t2, 'ad': ad, 'fa':fa, 'md': md, 'rd': rd,'subjectid': subjectid})\n",
    "\n",
    "tfrecord_dataset = tfDataSet.map(lambda x:_parse_(x)).shuffle(True).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = iter(tfrecord_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "for b in tfrecord_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = next(iter(tfrecord_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "a['fa'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "decoder = np.vectorize(lambda x: x.decode('UTF-8'))\n",
    "\n",
    "decoder(a['subjectid'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tf.strings.unicode_decode(a['subjectid'], input_encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  },
  "papermill": {
   "duration": 2570.863344,
   "end_time": "2019-11-21T19:49:10.728106",
   "environment_variables": {},
   "exception": true,
   "input_path": "Create TFRecords_256out.ipynb",
   "output_path": "xxx_out256.ipynb",
   "parameters": {},
   "start_time": "2019-11-21T19:06:19.864762",
   "version": "1.2.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}