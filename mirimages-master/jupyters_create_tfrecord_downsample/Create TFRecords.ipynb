{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import glob\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('intell_residual_train.csv')\n",
    "val_df = pd.read_csv('intell_residual_valid.csv')\n",
    "test_df = pd.read_csv('intell_residual_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[train_df['abcd_site']==16]\n",
    "val_df = val_df[val_df['abcd_site']==16]\n",
    "test_df = test_df[test_df['abcd_site']==16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "patht1 = './data_T1_lowerres/'\n",
    "patht2 = './data_T2_lowerres/'\n",
    "pathdef = './data_defusion_lowerres/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patht1 = './data_T1_lowerres_cropped/'\n",
    "patht2 = './data_T2_lowerres_cropped/'\n",
    "pathdef = './data_def_lowerres_cropped/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = glob.glob(patht1 + '*_T1.nii.gz') + glob.glob(patht2 + '*_T2.nii.gz') + glob.glob(pathdef + '*.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_id(text):\n",
    "    text_split = text.split('sub-')[1]\n",
    "    text_split = text_split.split('_', 1)\n",
    "    return(text_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = [extract_subject_id(x)[0] for x in all_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_subjects = list(dict.fromkeys(all_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11387"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filenames(sub, all_files):\n",
    "    return([x for x in all_files if sub in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data_T1_lowerres_cropped/sub-NDARINVR22TV84L_T1.nii.gz',\n",
       " './data_T2_lowerres_cropped/sub-NDARINVR22TV84L_T2.nii.gz',\n",
       " './data_def_lowerres_cropped/sub-NDARINVR22TV84L_DTI_tensor_mr_DTI_AD.nii.gz',\n",
       " './data_def_lowerres_cropped/sub-NDARINVR22TV84L_DTI_tensor_mr_DTI_FA.nii.gz',\n",
       " './data_def_lowerres_cropped/sub-NDARINVR22TV84L_DTI_tensor_mr_DTI_RD.nii.gz',\n",
       " './data_def_lowerres_cropped/sub-NDARINVR22TV84L_DTI_tensor_mr_DTI_MD.nii.gz']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_filenames(all_subjects[0], all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def parse_subject(subject, files):\n",
    "    for file in files:\n",
    "        img = nib.load(file)\n",
    "        data = np.array(img.dataobj)\n",
    "        if '_T1.' in file:\n",
    "            t1 = data.copy()\n",
    "            if t1.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_T2.' in file:\n",
    "            t2 = data.copy()\n",
    "            if t2.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_AD.' in file:\n",
    "            ad = data.copy()\n",
    "            if ad.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_FA.' in file:\n",
    "            fa = data.copy()\n",
    "            if fa.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_RD.' in file:\n",
    "            rd = data.copy()\n",
    "            if rd.shape != (64,64,64):\n",
    "                print('error')\n",
    "        if '_MD.' in file:\n",
    "            md = data.copy()\n",
    "            if md.shape != (64,64,64):\n",
    "                print('error')\n",
    "    example = tf.train.Example(features = tf.train.Features(\n",
    "        feature = {\n",
    "            't1':_bytes_feature(t1.tostring()),\n",
    "            't2':_bytes_feature(t2.tostring()),\n",
    "            'ad':_bytes_feature(ad.tostring()),\n",
    "            'fa':_bytes_feature(fa.tostring()),\n",
    "            'rd':_bytes_feature(rd.tostring()),\n",
    "            'md':_bytes_feature(md.tostring()),\n",
    "            'subjectid':_bytes_feature(subject.encode('utf-8'))\n",
    "        }))\n",
    "    return(example)\n",
    "\n",
    "def convert_to_records(all_subjects, all_files, sample=100, path = 'test4.tfrecords'):\n",
    "    print('writing to {}'.format(path))\n",
    "    counter = 0\n",
    "    with tf.io.TFRecordWriter(path) as writer:\n",
    "        for i in range(min(len(all_subjects), sample)):\n",
    "            subjectid = all_subjects[i]\n",
    "            files = get_filenames(subjectid, all_files)\n",
    "            if len(files)==6:\n",
    "                example = parse_subject(subjectid, files)\n",
    "                writer.write(example.SerializeToString())\n",
    "                if i%100==0:\n",
    "                    print('writing {}th image'.format(i))\n",
    "            else:\n",
    "                print(subjectid)\n",
    "                print(files)\n",
    "                print('missing images')\n",
    "                counter += 1\n",
    "    print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['subjectkey'] = train_df['subjectkey'].str.replace('_', '')\n",
    "val_df['subjectkey'] = val_df['subjectkey'].str.replace('_', '')\n",
    "test_df['subjectkey'] = test_df['subjectkey'].str.replace('_', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(all_subjects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing to t1t2_test_allimages_cropped_v4.tfrecords\n",
      "writing 0th image\n",
      "writing 100th image\n",
      "writing 200th image\n",
      "writing 300th image\n",
      "writing 400th image\n",
      "writing 500th image\n",
      "writing 600th image\n",
      "writing 700th image\n",
      "writing 800th image\n",
      "writing 900th image\n",
      "writing 1000th image\n",
      "writing 1100th image\n",
      "writing 1200th image\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#convert_to_records([x for x in all_subjects if x in list(train_df['subjectkey'])], all_files, sample=100000, path = 't1t2_train_allimages_cropped_v4.tfrecords')\n",
    "#convert_to_records([x for x in all_subjects if x in list(val_df['subjectkey'])], all_files, sample=100000, path = 't1t2_val_allimages_cropped_v4.tfrecords')\n",
    "convert_to_records([x for x in all_subjects if x in list(test_df['subjectkey'])], all_files, sample=100000, path = 't1t2_test_allimages_cropped_v4.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = [x for x in all_subjects if x in list(train_df['subjectkey'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVAA1BAPT1_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVGKT12ZAH_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVT1YTEV0D_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINV10T1UELH_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVT185E8M5_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVZT1J0KUC_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVKFJWT11B_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVANT1H5G3_T2.nii.gz\n",
      "t1 type\n",
      "error\n",
      "export/sub-NDARINVXUT1RZUJ_T2.nii.gz\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-d3fc353fce60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'T1'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    353\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;31m# Read array and scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0mraw_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_unscaled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mapply_read_scaling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nibabel/arrayproxy.py\u001b[0m in \u001b[0;36mget_unscaled\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    348\u001b[0m                                        \u001b[0moffset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_offset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m                                        \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m                                        mmap=self._mmap)\n\u001b[0m\u001b[1;32m    351\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mraw_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/nibabel/volumeutils.py\u001b[0m in \u001b[0;36marray_from_file\u001b[0;34m(shape, in_dtype, infile, offset, order, mmap)\u001b[0m\n\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'readinto'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         \u001b[0mdata_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 524\u001b[0;31m         \u001b[0mn_read\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    525\u001b[0m         \u001b[0mneeds_copy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m             \u001b[0;31m# Read a chunk of data from the file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    470\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_length\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0mread\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for subjectid in train_files:\n",
    "    files = get_filenames(subjectid, all_files)\n",
    "    for file in files:\n",
    "        img = nib.load(file)\n",
    "        data = np.array(img.dataobj)\n",
    "        if '_T1.' in file:\n",
    "            t1 = data.copy()\n",
    "            if t1.shape != (64,64,64):\n",
    "                print('t1 shape')\n",
    "                print('error')\n",
    "                print(file)\n",
    "            if t1.dtype != 'uint8':\n",
    "                print('t1 type')\n",
    "                print('error')\n",
    "                print(file)\n",
    "        if '_T2.' in file:\n",
    "            t2 = data.copy()\n",
    "            t2 = t2.astype(np.float32)\n",
    "            if t2.shape != (64,64,64):\n",
    "                print('t2 shape')\n",
    "                print('error')\n",
    "                print(file)\n",
    "            if t2.dtype != 'float32':\n",
    "                print('t2 type')\n",
    "                print('error')\n",
    "                print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2.astype(np.float32).dtype == 'float32'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "126M\tt1t2_train_sample100.tfrecords\r\n"
     ]
    }
   ],
   "source": [
    "!du -sh t1t2_train_sample100.tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfDataSet = tf.data.TFRecordDataset('t1t2_val_site16_allimages_v4.tfrecords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <function _parse_ at 0x7fb862a598c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n",
      "WARNING: Entity <function _parse_ at 0x7fb862a598c8> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: \n"
     ]
    }
   ],
   "source": [
    "read_features = {\n",
    "    't1': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    't2': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'ad': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'fa': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'md': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'rd': tf.io.FixedLenFeature([], dtype=tf.string),\n",
    "    'subjectid': tf.io.FixedLenFeature([], dtype=tf.string)\n",
    "}\n",
    "\n",
    "\n",
    "def _parse_(serialized_example, decoder = np.vectorize(lambda x: x.decode('UTF-8'))):\n",
    "    example = tf.io.parse_single_example(serialized_example, read_features)\n",
    "    t1 = tf.reshape(tf.io.decode_raw(example['t1'], tf.int8), (64,64,64))\n",
    "    t2 = tf.reshape(tf.io.decode_raw(example['t2'], tf.float32), (64,64,64))\n",
    "    ad = tf.reshape(tf.io.decode_raw(example['ad'], tf.float32), (64,64,64))\n",
    "    fa = tf.reshape(tf.io.decode_raw(example['fa'], tf.float32), (64,64,64))\n",
    "    md = tf.reshape(tf.io.decode_raw(example['md'], tf.float32), (64,64,64))\n",
    "    rd = tf.reshape(tf.io.decode_raw(example['rd'], tf.float32), (64,64,64))\n",
    "    subjectid = example['subjectid']\n",
    "    return ({'t1': t1, 't2': t2, 'ad': ad, 'fa':fa, 'md': md, 'rd': rd,'subjectid': subjectid})\n",
    "\n",
    "tfrecord_dataset = tfDataSet.map(lambda x:_parse_(x)).shuffle(True).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = iter(tfrecord_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in tfrecord_dataset:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = next(iter(tfrecord_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 64, 64, 64])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a['fa'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NDARINVJHF93Z1H', 'NDARINVFX2LPCN8', 'NDARINVR22TV84L',\n",
       "       'NDARINVPB7TWVGE', 'NDARINV7NKVRYKG', 'NDARINVT6WVPL1D',\n",
       "       'NDARINV1FRN7VDM', 'NDARINVMN01YD5J', 'NDARINVAZ0PNBVG',\n",
       "       'NDARINV52CVLNFF', 'NDARINVRHX34P95', 'NDARINV4VK7GGEN',\n",
       "       'NDARINVCMGFWG2E', 'NDARINVZKDXUC63', 'NDARINVEJ1NL7U8',\n",
       "       'NDARINV43M1L7PL', 'NDARINVL18G63XV', 'NDARINV0UMM15GY',\n",
       "       'NDARINV3Z6H844T', 'NDARINV1PE0ZVR4', 'NDARINV6WW1A9ER',\n",
       "       'NDARINV8JJXHDK8', 'NDARINV8LUWPYZD', 'NDARINVZW8G4W5A',\n",
       "       'NDARINV2AD1P5NV', 'NDARINV2547FH92', 'NDARINVPTL6W25B',\n",
       "       'NDARINVKNRU5BYD', 'NDARINVPZE8ABE3', 'NDARINVMH4PJ6L9',\n",
       "       'NDARINVRN9A0LAB', 'NDARINVUL9WW7ET'], dtype='<U15')"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder = np.vectorize(lambda x: x.decode('UTF-8'))\n",
    "\n",
    "decoder(a['subjectid'].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[78, 68, 65, 82, 73, 78, 86, 74, 72, 70, 57, 51, 90, 49, 72], [78, 68, 65, 82, 73, 78, 86, 70, 88, 50, 76, 80, 67, 78, 56], [78, 68, 65, 82, 73, 78, 86, 82, 50, 50, 84, 86, 56, 52, 76], [78, 68, 65, 82, 73, 78, 86, 80, 66, 55, 84, 87, 86, 71, 69], [78, 68, 65, 82, 73, 78, 86, 55, 78, 75, 86, 82, 89, 75, 71], [78, 68, 65, 82, 73, 78, 86, 84, 54, 87, 86, 80, 76, 49, 68], [78, 68, 65, 82, 73, 78, 86, 49, 70, 82, 78, 55, 86, 68, 77], [78, 68, 65, 82, 73, 78, 86, 77, 78, 48, 49, 89, 68, 53, 74], [78, 68, 65, 82, 73, 78, 86, 65, 90, 48, 80, 78, 66, 86, 71], [78, 68, 65, 82, 73, 78, 86, 53, 50, 67, 86, 76, 78, 70, 70], [78, 68, 65, 82, 73, 78, 86, 82, 72, 88, 51, 52, 80, 57, 53], [78, 68, 65, 82, 73, 78, 86, 52, 86, 75, 55, 71, 71, 69, 78], [78, 68, 65, 82, 73, 78, 86, 67, 77, 71, 70, 87, 71, 50, 69], [78, 68, 65, 82, 73, 78, 86, 90, 75, 68, 88, 85, 67, 54, 51], [78, 68, 65, 82, 73, 78, 86, 69, 74, 49, 78, 76, 55, 85, 56], [78, 68, 65, 82, 73, 78, 86, 52, 51, 77, 49, 76, 55, 80, 76], [78, 68, 65, 82, 73, 78, 86, 76, 49, 56, 71, 54, 51, 88, 86], [78, 68, 65, 82, 73, 78, 86, 48, 85, 77, 77, 49, 53, 71, 89], [78, 68, 65, 82, 73, 78, 86, 51, 90, 54, 72, 56, 52, 52, 84], [78, 68, 65, 82, 73, 78, 86, 49, 80, 69, 48, 90, 86, 82, 52], [78, 68, 65, 82, 73, 78, 86, 54, 87, 87, 49, 65, 57, 69, 82], [78, 68, 65, 82, 73, 78, 86, 56, 74, 74, 88, 72, 68, 75, 56], [78, 68, 65, 82, 73, 78, 86, 56, 76, 85, 87, 80, 89, 90, 68], [78, 68, 65, 82, 73, 78, 86, 90, 87, 56, 71, 52, 87, 53, 65], [78, 68, 65, 82, 73, 78, 86, 50, 65, 68, 49, 80, 53, 78, 86], [78, 68, 65, 82, 73, 78, 86, 50, 53, 52, 55, 70, 72, 57, 50], [78, 68, 65, 82, 73, 78, 86, 80, 84, 76, 54, 87, 50, 53, 66], [78, 68, 65, 82, 73, 78, 86, 75, 78, 82, 85, 53, 66, 89, 68], [78, 68, 65, 82, 73, 78, 86, 80, 90, 69, 56, 65, 66, 69, 51], [78, 68, 65, 82, 73, 78, 86, 77, 72, 52, 80, 74, 54, 76, 57], [78, 68, 65, 82, 73, 78, 86, 82, 78, 57, 65, 48, 76, 65, 66], [78, 68, 65, 82, 73, 78, 86, 85, 76, 57, 87, 87, 55, 69, 84]]>"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.unicode_decode(a['subjectid'], input_encoding='UTF-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
